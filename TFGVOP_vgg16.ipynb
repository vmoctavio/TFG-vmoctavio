{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TFGVOP_vgg16.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vmoctavio/TFG-vmoctavio/blob/master/TFGVOP_vgg16.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVUDb-Et5NQe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "cfc2cf30-fc32-4a55-973e-a9c36d5c4764"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGF5BCckr9KE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Número de veces que se entrena la red\n",
        "EPOCHS = 5\n",
        "# Initial Learning Rate\n",
        "INIT_LR = 0.00001\n",
        "# Tamaño del lote\n",
        "BATCH_SIZE = 32\n",
        "# Tamaño de la imagen: ancho\n",
        "width=256\n",
        "# Tamaño de la imagen: alto\n",
        "height=256\n",
        "# Número de canales de la imagen\n",
        "depth=3\n",
        "# Porcentaje división dataset en train y test\n",
        "TEST_SIZE = 0.1\n",
        "# Porcentaje división dataset en train y validation (a partir del subconjunto anterior)\n",
        "VALID_SIZE = 0.2\n",
        "# Division del dataset no aleatorio\n",
        "RANDOM_STATE = 42\n",
        "# Directorio de trabajo donde está el dataset\n",
        "directory_root = '/content/drive/My Drive/Dataset_vid_prueba_dest/'\n",
        "# Directorio de trabajo donde se generan los logs de salida del proceso\n",
        "directory_log = '/content/drive/My Drive/logs/'\n",
        "# Directorio de trabajo donde se generan los modelos de salida del proceso\n",
        "directory_modelos = '/content/drive/My Drive/modelos/'\n",
        "# Número de registros a cargar por directorio\n",
        "CONTREG = 50\n",
        "# Training progress; el 1 muestra una barra de progreso animada por epoch\n",
        "VERBOSE = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqHw67jhtlm1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -----------------------------------------------------------------------------------------------\n",
        "# Imports necesarios\n",
        "# -----------------------------------------------------------------------------------------------\n",
        "#\n",
        "# Arquitectura de red a probar\n",
        "from tensorflow.keras.applications import vgg16\n",
        "#\n",
        "# API de alto nivel para procesos de Deep Learning\n",
        "import keras\n",
        "#\n",
        "# Uso de funciones del backend\n",
        "from keras import backend as K\n",
        "#\n",
        "# Uso de funciones de manejo de imágenes\n",
        "from keras.preprocessing import image\n",
        "#\n",
        "# Convertir una imagen en una matriz NumPy \n",
        "from keras.preprocessing.image import img_to_array\n",
        "#\n",
        "# Convierte un vector de clase (enteros) en una matriz de clase binaria\n",
        "from keras.utils import to_categorical\n",
        "#\n",
        "# Optimizar para compilar un modelo\n",
        "from keras.optimizers import Adam\n",
        "#\n",
        "# Usar comandos del sistema operativo\n",
        "import os\n",
        "#\n",
        "# Manejo de arrays \n",
        "import numpy as np\n",
        "#\n",
        "# Para manipular fechas y horas\n",
        "import datetime\n",
        "#\n",
        "# Funciones matemáticas \n",
        "import math\n",
        "#\n",
        "# Librería para generar gráficas\n",
        "import matplotlib.pyplot as plt\n",
        "#\n",
        "# Entorno de trabajo para redes deep learning\n",
        "import tensorflow as tf\n",
        "#\n",
        "# Convierte un modelo de Keras a diagrama y lo guarda en un archivo\n",
        "from tensorflow.keras.utils import plot_model \n",
        "#\n",
        "# Dividir un dataset en dos\n",
        "from sklearn.model_selection import train_test_split\n",
        "#\n",
        "# Visualizar la matriz de confusión - rendimiento de un algoritmo\n",
        "from sklearn.metrics import confusion_matrix  \n",
        "#\n",
        "# Visualizar informe con las principales métricas de clasificación\n",
        "from sklearn.metrics import classification_report  \n",
        "#\n",
        "# Librería para el análisis de datos\n",
        "import pandas as pd  \n",
        "#\n",
        "# Librería para visualización de datos y gráficos\n",
        "import seaborn as sn  \n",
        "#\n",
        "# Módulo para control de excepciones\n",
        "import sys\n",
        "#\n",
        "# Devuelve una lista que contiene el nombre de las entradas en el directorio de la ruta del parámetro.\n",
        "from os import listdir\n",
        "#\n",
        "# Librería para el procesamiento de imágenes\n",
        "import cv2\n",
        "#\n",
        "# Librería para serializar objetos\n",
        "import pickle\n",
        "#\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------------------------------------------\n",
        "# Inicio del proceso\n",
        "# -----------------------------------------------------------------------------------------------\n",
        "print(\"[INFO]\", \n",
        "    datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "    \"Inicio del proceso\",\n",
        "    \"vgg16\")\n",
        "#    os.path.basename(__file__))\n",
        "#"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tI8hSioxu626",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -----------------------------------------------------------------------------------------------\n",
        "# Inicialización de variables\n",
        "# -----------------------------------------------------------------------------------------------\n",
        "#\n",
        "image_list=[]       # array de array's resultado de convertir las imágenes del directorio\n",
        "image_labels=[]     # array de array's de etiquetas\n",
        "labels=[]           # array con las distintas etiquetas del dataset\n",
        "# \n",
        "# Intervalo para las coordenadas de la gráfica\n",
        "INTERVALO = math.ceil(EPOCHS/10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5rWjJClvIId",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"[INFO]\", \n",
        "    datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "    \"Llamada al proceso TFGVOP_load_dataset \")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jv7eE7B6vMvQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Tamaño por defecto de las imágenes\n",
        "default_image_size = tuple((height, width))\n",
        "#\n",
        "# -----------------------------------------------------------------------------------------------\n",
        "# Función para redimensionar una imagen y convertirla en array\n",
        "# -----------------------------------------------------------------------------------------------\n",
        "#\n",
        "def convert_image_to_array(image_dir):\n",
        "    try:\n",
        "        # Carga la imagen del fichero del parámetro\n",
        "        image = cv2.imread(image_dir)\n",
        "        if image is not None:   # Detecta si el fichero existe\n",
        "            # Redimensiona la imagen al tamaño especificado en la variable default_image_size\n",
        "            image = cv2.resize(image, default_image_size)\n",
        "            return img_to_array(image) # Devuelve como array la imagen del parámetro\n",
        "        else :\n",
        "            return np.array([]) # Devuelve un array vacío\n",
        "    except Exception as e: # Controla cualquier error que se produzca en la función\n",
        "        print(\"[ERROR]\", \n",
        "            datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "            sys.exc_info()[0],\n",
        "            sys.exc_info()[1],\n",
        "            sys.exc_info()[2])\n",
        "        return None\n",
        "#\n",
        "# -----------------------------------------------------------------------------------------------\n",
        "# Proceso principal: lee las carpetas del directorio y genera los correspondientes arrays para\n",
        "#                    imágenes y etiquetas\n",
        "# -----------------------------------------------------------------------------------------------\n",
        "#\n",
        "def load_dataset_process(directory_root):\n",
        "#   \n",
        "    cont_labels = 0         # Contador de etiquetas diferentes\n",
        "    image_label = []        # Array con el nombre de las etiquetas\n",
        "    labels = []             # Array con las distintas etiquetas del dataset\n",
        "    label_list = []         # Array de Array's de etiquetas\n",
        "    image_list = []         # Array de Array's de imágenes\n",
        "#\n",
        "    try:\n",
        "        root_dir = listdir(directory_root)      # Genera una lista con los directorios existentes\n",
        "#\n",
        "        for directory in root_dir :\n",
        "            # elimina .DS_Store de la lista en caso de existir\n",
        "            if directory == \".DS_Store\" :\n",
        "                root_dir.remove(directory)\n",
        "#\n",
        "        plant_disease_folder_list = listdir(f\"{directory_root}\") # Genera una lista con los directorios existentes\n",
        "        for disease_folder in plant_disease_folder_list:\n",
        "            # elimina .DS_Store de la lista en caso de existir\n",
        "            if disease_folder == \".DS_Store\" :\n",
        "                plant_disease_folder_list.remove(disease_folder)\n",
        "#\n",
        "        for plant_disease_folder in plant_disease_folder_list:  # Nos recorremos todos los directorios existentes\n",
        "            print(f\"[INFO]\", \n",
        "                datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "                \"Procesando el directorio... \",\n",
        "                plant_disease_folder)\n",
        "#\n",
        "            total_images_origen = 0 # contador imágenes por cada directorio\n",
        "#\n",
        "            labels.append(plant_disease_folder)   # Lista con las diferentes etiquetas\n",
        "            cont_labels = cont_labels + 1\n",
        "#        \n",
        "            # Genera una lista con todos los archivos de un directorio concreto\n",
        "            plant_disease_image_list = listdir(f\"{directory_root}/{plant_disease_folder}/\")\n",
        "# \n",
        "            for single_plant_disease_image in plant_disease_image_list:  # Nos recorremos todos los archivos de un directorio concreto\n",
        "                # elimina .DS_Store de la lista en caso de existir\n",
        "                if single_plant_disease_image == \".DS_Store\" :\n",
        "                    plant_disease_image_list.remove(single_plant_disease_image)\n",
        "#\n",
        "            for image in plant_disease_image_list[:CONTREG]: # Nos recorremos todos los archivos de un directorio concreto\n",
        "                image_directory = f\"{directory_root}/{plant_disease_folder}/{image}\"\n",
        "                # Si el archivo tiene extensión jpg o JPG lo tratamos \n",
        "                if image_directory.endswith(\".jpg\") == True or image_directory.endswith(\".JPG\") == True:\n",
        "                    #  print(\"[INFO]\",\n",
        "                    #      datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "                    #      \"Cargando imagen ... \",image)\n",
        "                    #      Carga lista de imágenes y etiquetas\n",
        "                    image_list.append(convert_image_to_array(image_directory))  # Convierte imagen a array\n",
        "                    image_label.append(cont_labels-1)\n",
        "\n",
        "\n",
        "#                    image_label.append(plant_disease_folder)\n",
        "                    total_images_origen = total_images_origen + 1 #  contador imágenes por cada directorio\n",
        "#\n",
        "            print(\"[INFO]\", \n",
        "                datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "                \"Total imágenes del directorio ... \",\n",
        "                plant_disease_folder,total_images_origen)\n",
        "#\n",
        "        print(\"[INFO]\",\n",
        "            datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "            \"Proceso de carga de imágenes completado \")\n",
        "\n",
        "        #\n",
        "        # -----------------------------------------------------------------------------------------------\n",
        "        # Obtener el tamño de la imagen\n",
        "        # -----------------------------------------------------------------------------------------------\n",
        "        #\n",
        "        #image_size = len(image_list) ver si esto se puede borar   ****************************\n",
        "        #\n",
        "        # -----------------------------------------------------------------------------------------------\n",
        "        # Transforma las etiquetas de las imágenes mediante LabelBinarizer\n",
        "        # -----------------------------------------------------------------------------------------------\n",
        "        #\n",
        "#        label_binarizer = LabelBinarizer()\n",
        "#        label_list = label_binarizer.fit_transform(image_label)\n",
        "        # esto creo que podría sobrar, no sé para qué es.\n",
        "        # si se quita, también sobraría el input pickle\n",
        "#        pickle.dump(label_binarizer,open('label_transform.pkl', 'wb'))    \n",
        "    #\n",
        "        print(\"[INFO]\",\n",
        "            datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "            \"Total Etiquetas... \",\n",
        "            cont_labels)\n",
        "    #       se puede borar todo lo relacionado con binarizer \n",
        "#        print(\"[INFO]\",\n",
        "#            datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "#            \"Etiquetas ... \",\n",
        "#            label_binarizer.classes_)\n",
        "        #\n",
        "        # -----------------------------------------------------------------------------------------------\n",
        "        # ver si esto se puede borrar\n",
        "        # -----------------------------------------------------------------------------------------------\n",
        "        #\n",
        "        #    np_image_list = np.array(image_list, dtype=np.float16) / 225.0   # no sé para qué es lo del / 225.0\n",
        "        #   hace un scalar\n",
        "        # -----------------------------------------------------------------------------------------------\n",
        "        # xxxxxx\n",
        "        # -----------------------------------------------------------------------------------------------\n",
        "\n",
        "    except Exception as e: # Controla cualquier error que se produzca en la función\n",
        "        print(\"[ERROR]\",\n",
        "            datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "            sys.exc_info()[0],\n",
        "            sys.exc_info()[1],\n",
        "            sys.exc_info()[2])\n",
        "    #\n",
        "    print(\"[INFO]\", \n",
        "        datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "        \"Fin del proceso\",\n",
        "        \"load_dataset\")\n",
        "    #    os.path.basename(__file__))\n",
        "    #\n",
        "    # -----------------------------------------------------------------------------------------------\n",
        "    # Fin de la ejecución y devolución del resultado en los parámetros de salida\n",
        "    # -----------------------------------------------------------------------------------------------\n",
        "    #\n",
        "    return(image_label,image_list,labels)\n",
        "#\n",
        "# -----------------------------------------------------------------------------------------------\n",
        "# Fin del proceso\n",
        "# -----------------------------------------------------------------------------------------------\n",
        "#"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WEQaXw3vdU-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(image_labels,image_list,labels) = load_dataset_process(directory_root)\n",
        "#\n",
        "print(\"[INFO]\", \n",
        "    datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "    \"Imágenes cargadas. Número total de imágenes para procesar:  \",\n",
        "    len(image_list),\n",
        "    \". Número total de clases diferentes:\",\n",
        "    len(labels))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-g0r7yM8v77i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#\n",
        "# -----------------------------------------------------------------------------------------------\n",
        "# Calculamos el número de clases diferentes\n",
        "# -----------------------------------------------------------------------------------------------\n",
        "#\n",
        "n_classes = len(labels)\n",
        "#\n",
        "# -----------------------------------------------------------------------------------------------\n",
        "# Convertir la lista de imágenes y etiquetas en arrays Numpy\n",
        "# -----------------------------------------------------------------------------------------------\n",
        "#\n",
        "np_image_list = np.array(image_list, dtype=np.uint8)\n",
        "y = np.array(image_labels)\n",
        "#"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mu1VQZQBwfNd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -----------------------------------------------------------------------------------------------\n",
        "# División de los datos (imágenes y etiquetas) \n",
        "# en archivos para entrenamiento (train) y pruebas (test)\n",
        "# -----------------------------------------------------------------------------------------------\n",
        "#\n",
        "print(\"[INFO]\", \n",
        "    datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "    \"Dividiendo datos en train y test...\")\n",
        "#\n",
        "x_train, x_test, y_train, y_test = train_test_split(np_image_list,          # array de imágenes\n",
        "                                                    y,                      # array de etiquetas\n",
        "                                                    test_size=TEST_SIZE,    # % para el archivo de test \n",
        "                                                    random_state = RANDOM_STATE)\n",
        "#\n",
        "print(\"[INFO]\", \n",
        "    datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "    \"Training data shape (x_train): \",\n",
        "    x_train.shape)\n",
        "print(\"[INFO]\", \n",
        "    datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "    \"Training data shape (y_train): \",\n",
        "    y_train.shape)\n",
        "#\n",
        "print(\"[INFO]\", \n",
        "    datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "    \"Testing data shape (x_test): \",\n",
        "    x_test.shape)\n",
        "print(\"[INFO]\", \n",
        "    datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "    \"Testing data shape (y_test): \",\n",
        "    y_test.shape)\n",
        "#"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_MK5wtw96ZY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -----------------------------------------------------------------------------------------------\n",
        "# Cambiamos los tipos y escalamos los pixeles en el ranto [0,1]\n",
        "# -----------------------------------------------------------------------------------------------\n",
        "#\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train = x_train / 255.\n",
        "x_test = x_test / 255.\n",
        "#\n",
        "# -----------------------------------------------------------------------------------------------\n",
        "# Convierte un vector de clase (enteros) en una matriz de clase binaria\n",
        "# -----------------------------------------------------------------------------------------------\n",
        "# \n",
        "y_train_one_hot = to_categorical(y_train)\n",
        "y_test_one_hot = to_categorical(y_test)\n",
        "#"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "miQnH1ED9_J4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -----------------------------------------------------------------------------------------------\n",
        "# División de los datos (imágenes y etiquetas) \n",
        "# en archivos para entrenamiento (train) y validación (valid)\n",
        "# a partir de los archivos de entrenamiento que se generaron en la primera división.\n",
        "# -----------------------------------------------------------------------------------------------\n",
        "#\n",
        "print(\"[INFO]\",\n",
        "    datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "    \"Dividiendo datos en train y valid...\")\n",
        "#\n",
        "x_train, x_valid, train_label, valid_label = train_test_split(x_train,          # array de imágenes \n",
        "                                                    y_train_one_hot,            # array de etiquetas\n",
        "                                                    test_size=VALID_SIZE,       # % para el archivo de validación  \n",
        "                                                    random_state = RANDOM_STATE)\n",
        "#\n",
        "print(\"[INFO]\", \n",
        "    datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "    \"Training data shape (x_train): \",\n",
        "    x_train.shape)\n",
        "print(\"[INFO]\", \n",
        "    datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "    \"Training data shape (train_label): \",\n",
        "    train_label.shape)\n",
        "#\n",
        "print(\"[INFO]\", \n",
        "    datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "    \"Validating data shape (x_valid): \",\n",
        "    x_valid.shape)\n",
        "print(\"[INFO]\", \n",
        "    datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "    \"Validating data shape (valid_label): \",\n",
        "    valid_label.shape)\n",
        "#"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gnm5tzpT-Dyg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -----------------------------------------------------------------------------------------------\n",
        "# Inicialización archivo de registro (LOG_DIR) y Tensorboard \n",
        "# -----------------------------------------------------------------------------------------------\n",
        "#\n",
        "LOG_DIR=directory_log + 'vgg16_' + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "# Frecuencia (en epochs) a la que se calculan los histogramas de activación para las capas del modelo.\n",
        "v_histogram_freq=1  \n",
        "#\n",
        "print(\"[INFO]\",\n",
        "    datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "    \"Generado log en... \",\n",
        "    LOG_DIR)\n",
        "#\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=LOG_DIR,      # Directorio de registro\n",
        "                                                    histogram_freq=v_histogram_freq,       \n",
        "                                                    write_graph=True,       # Si visualizar el gráfico\n",
        "                                                    write_images=True,      # Si visualizar imágenes\n",
        "                                                    update_freq='epoch',    # Las métricas se generan por cada epoch\n",
        "                                                    profile_batch=2)        # Perfilar el segundo lote\n",
        "#"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KcAIIrw4-LJ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -----------------------------------------------------------------------------------------------\n",
        "# Inicializa input_shape en función del formato de la imagen\n",
        "# -----------------------------------------------------------------------------------------------\n",
        "#\n",
        "inputShape = (height, width, depth)\n",
        "chanDim = -1\n",
        "if K.image_data_format() == \"channels_first\":\n",
        "    inputShape = (depth, height, width)\n",
        "    chanDim = 1\n",
        "#"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FoF_jnQu-P0m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -----------------------------------------------------------------------------------------------\n",
        "# Función para crear el modelo vgg16\n",
        "# -----------------------------------------------------------------------------------------------\n",
        "#\n",
        "def create_vgg16():\n",
        "    model = vgg16.VGG16(include_top=True,       # Incluir las 3 capas totalmente conectadas en la parte superior de la red\n",
        "                        weights=None,           # Inicialización random (no partir de pre-entrenadas de imagenet)\n",
        "                        input_tensor=None,      # No usar tensor como entrada de imágenes\n",
        "                        input_shape=inputShape, # Resolución de las imágenes de entrada\n",
        "                        pooling=None,           # Modo agrupación de características\n",
        "                        classes=n_classes)      # Número de clases\n",
        "    return model\n",
        "#"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6GrXMvt-T50",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -----------------------------------------------------------------------------------------------\n",
        "# Llamada a la función para crear el modelo\n",
        "# -----------------------------------------------------------------------------------------------\n",
        "#\n",
        "vgg16_model = create_vgg16()  \n",
        "#"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMedj221-bNN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -----------------------------------------------------------------------------------------------\n",
        "# Inicializa parámetros para el optimizador ADAM \n",
        "# -----------------------------------------------------------------------------------------------\n",
        "#\n",
        "opt = tf.keras.optimizers.Adam(lr=INIT_LR,                  # Initial Learning Rate\n",
        "                               decay=INIT_LR / EPOCHS)      # Disminución de Learning Rate \n",
        "#"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMntpdnLDXEY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -----------------------------------------------------------------------------------------------\n",
        "# Configuración / compilación del proceso de aprendizaje\n",
        "# -----------------------------------------------------------------------------------------------\n",
        "#\n",
        "vgg16_model.compile(loss='categorical_crossentropy',        # Función de pérdida\n",
        "                    optimizer=opt,                          # Optimizador \n",
        "                    metrics=['acc', 'mean_squared_error'])  # Métricas del proceso \n",
        "#"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xUSSnkyqDbm6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -----------------------------------------------------------------------------------------------\n",
        "# Imprime una representación resumida del modelo\n",
        "# -----------------------------------------------------------------------------------------------\n",
        "#\n",
        "vgg16_model.summary()\n",
        "#"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxWxxdhsDfBa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -----------------------------------------------------------------------------------------------\n",
        "# Creamos el directorio destino de las gráficas, si no existe \n",
        "# -----------------------------------------------------------------------------------------------\n",
        "try:\n",
        "    os.stat(directory_log)\n",
        "except:\n",
        "    os.mkdir(directory_log)\n",
        "#\n",
        "try:\n",
        "    os.stat(directory_log + 'modelos')\n",
        "except:\n",
        "    os.mkdir(directory_log + 'modelos')\n",
        "#\n",
        "#"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVV9wEJ5D4f8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -----------------------------------------------------------------------------------------------\n",
        "# Convierte un modelo de Keras a diagrama y lo guarda en un archivo\n",
        "# -----------------------------------------------------------------------------------------------\n",
        "#\n",
        "tf.keras.utils.plot_model(model=vgg16_model,\n",
        "                       to_file=directory_log + 'modelos/' + 'Plotmodel_vgg16.png',\n",
        "                       show_shapes=True,\n",
        "                       show_layer_names=True,\n",
        "                       rankdir='TB',\n",
        "                       expand_nested=True,\n",
        "                       dpi=96)\n",
        "#"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rYNu2C2D8jO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -----------------------------------------------------------------------------------------------\n",
        "# Ejecución / entrenamiento de la red\n",
        "# -----------------------------------------------------------------------------------------------\n",
        "#\n",
        "vgg16 = vgg16_model.fit(x_train,                                    # Imágenes de entrenamiento\n",
        "                        train_label,                                # Etiquetas entrenamiento \n",
        "                        batch_size=BATCH_SIZE,                      # Tamaño del lote \n",
        "                        epochs=EPOCHS,                              # Número de veces que se entrena la red\n",
        "                        verbose=VERBOSE,                            # Barra de progreso \n",
        "                        validation_data=(x_valid, valid_label),     # Datos de validación (imágenes y etiquetas)\n",
        "                        shuffle=True,                               # Reordenar los lotes al comienzo de cada epoch\n",
        "                        callbacks=[tensorboard_callback])           # Configuración de Tensorboard   \n",
        "#"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNboJS_FM0gK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -----------------------------------------------------------------------------------------------\n",
        "# Representación de las métricas de entrenamiento y validación\n",
        "# -----------------------------------------------------------------------------------------------\n",
        "#                               Training Accuracy vs Validation Accuracy\n",
        "plt.figure(0)  \n",
        "plt.plot(vgg16.history['acc'],'r')  \n",
        "plt.plot(vgg16.history['val_acc'],'g')  \n",
        "plt.xticks(np.arange(0, EPOCHS, INTERVALO))\n",
        "plt.rcParams['figure.figsize'] = (8, 6)  \n",
        "plt.xlabel(\"Num of Epochs\")  \n",
        "plt.ylabel(\"Accuracy\")  \n",
        "plt.title(\"Training Accuracy vs Validation Accuracy en vgg16\")  \n",
        "plt.legend(['train','validation'])\n",
        "plt.savefig(directory_log + 'modelos/' + 'TrainingAccuracyvsValidationAccuracy_en_vgg16.png')  \n",
        "\n",
        "#                               Training Loss vs Validation Loss\n",
        "plt.figure(1)  \n",
        "plt.plot(vgg16.history['loss'],'r')  \n",
        "plt.plot(vgg16.history['val_loss'],'g')  \n",
        "plt.xticks(np.arange(0, EPOCHS, INTERVALO))\n",
        "plt.rcParams['figure.figsize'] = (8, 6)  \n",
        "plt.xlabel(\"Num of Epochs\")  \n",
        "plt.ylabel(\"Loss\")  \n",
        "plt.title(\"Training Loss vs Validation Loss en vgg16\")  \n",
        "plt.legend(['train','validation'])\n",
        "plt.savefig(directory_log + 'modelos/' + 'TrainingLossvsValidationLoss_en_vgg16.png')  \n",
        "\n",
        "#                               Training mse vs Validation mse\n",
        "plt.figure(2)  \n",
        "plt.plot(vgg16.history['mean_squared_error'],'r')  \n",
        "plt.plot(vgg16.history['val_mean_squared_error'],'g')  \n",
        "plt.xticks(np.arange(0, EPOCHS, INTERVALO))\n",
        "plt.rcParams['figure.figsize'] = (8, 6)  \n",
        "plt.xlabel(\"Num of Epochs\")  \n",
        "plt.ylabel(\"mean_squared_error\")  \n",
        "plt.title(\"Training mse vs Validation mse en vgg16\")  \n",
        "plt.legend(['train','validation'])\n",
        "plt.savefig(directory_log + 'modelos/' + 'TrainingmsevsValidationmse_en_vgg16.png')  \n",
        "#\n",
        "plt.show()\n",
        "#\n",
        "# ver por qué da error el mse....."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6Ps4QTnN-AX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -----------------------------------------------------------------------------------------------\n",
        "# Calcular la precisión del modelo con el conjunto de datos de test \n",
        "# los cuales no han participado en el proceso de entrenamiento y validación\n",
        "# -----------------------------------------------------------------------------------------------\n",
        "#\n",
        "print(\"[INFO]\",\n",
        "    datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "    \"Calculando la precisión del modelo vgg16... \")\n",
        "#\n",
        "resultado_test = vgg16_model.evaluate(x_test,\n",
        "                              y_test_one_hot)\n",
        "#\n",
        "print(\"[INFO]\",\n",
        "    datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "    f\"Test Accuracy vgg16: {resultado_test[1]*100}\")\n",
        "#\n",
        "print(\"[INFO]\",\n",
        "    datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "    f\"Test Loss vgg16: {resultado_test[0]*100}\")  # no sé si el loss se multiplica o no\n",
        "#"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDTJFuMHOEJF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -----------------------------------------------------------------------------------------------\n",
        "# Genera las predicciones de salida para el conjunto de datos test\n",
        "# -----------------------------------------------------------------------------------------------\n",
        "#\n",
        "predicted_classes_test = vgg16_model.predict(x_test)\n",
        "#\n",
        "predicted_classes=[]\n",
        "for predicted_image in predicted_classes_test:\n",
        "    predicted_classes.append(predicted_image.tolist().index(max(predicted_image)))\n",
        "#\n",
        "predicted_classes=np.array(predicted_classes)\n",
        "#"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DYxiIoZOKF0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -----------------------------------------------------------------------------------------------\n",
        "# Convertir array de etiquetas de test\n",
        "# -----------------------------------------------------------------------------------------------\n",
        "#\n",
        "y_test_aux = np.array(y_test)\n",
        "#\n",
        "predicted_classes.shape, y_test.shape\n",
        "#"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6e_4BG2GOPU1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -----------------------------------------------------------------------------------------------\n",
        "# Calcular predicciones correctas\n",
        "# -----------------------------------------------------------------------------------------------\n",
        "#\n",
        "correct = np.where(predicted_classes==y_test)[0]\n",
        "#\n",
        "print(\"[INFO]\",\n",
        "    datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "    \"Se han encontrado %d etiquetas correctas\" % len(correct))\n",
        "#"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCm_8vomOUZr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -----------------------------------------------------------------------------------------------\n",
        "# Ejemplos de predicciones correctas\n",
        "# -----------------------------------------------------------------------------------------------\n",
        "#\n",
        "for i, correct in enumerate(correct[0:9]):\n",
        "    plt.subplot(3,3,i+1)\n",
        "    plt.imshow(x_test[correct].reshape(256,256,3), cmap='gray', interpolation='none')\n",
        "    plt.title(\"{} / {}\".format(labels[predicted_classes[correct]],labels[y_test[correct]]))\n",
        "    plt.tight_layout()\n",
        "#\n",
        "plt.savefig(directory_log + 'modelos/' + 'Ejemploprediccionescorrectas_en_vgg16.png')  \n",
        "plt.show()  \n",
        "#"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5KamwPAOZgH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -----------------------------------------------------------------------------------------------\n",
        "# Calcular predicciones incorrectas\n",
        "# -----------------------------------------------------------------------------------------------\n",
        "#\n",
        "incorrect = np.where(predicted_classes!=y_test)[0]\n",
        "#\n",
        "print(\"[INFO]\",\n",
        "    datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "    \"Se han encontrado %d etiquetas incorrectas\" % len(incorrect))\n",
        "#"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZSjo5beOcXz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -----------------------------------------------------------------------------------------------\n",
        "# Ejemplos de predicciones incorrecatas\n",
        "# -----------------------------------------------------------------------------------------------\n",
        "#\n",
        "# print(\"Calculado / Correcto\")\n",
        "for i, incorrect in enumerate(incorrect[0:9]):\n",
        "    plt.subplot(3,3,i+1)\n",
        "    plt.imshow(x_test[incorrect].reshape(256,256,3), cmap='gray', interpolation='none')\n",
        "    plt.title(\"{} / {}\".format(labels[predicted_classes[incorrect]],labels[y_test[incorrect]]))\n",
        "    plt.tight_layout()\n",
        "#\n",
        "plt.savefig(directory_log + 'modelos/' + 'Ejemploprediccionesincorrectas_en_vgg16.png')  \n",
        "plt.show()  \n",
        "#"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0aeQK1hoOfdM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -----------------------------------------------------------------------------------------------\n",
        "# Matriz de confusión para evaluación de falsos positivos y falsos negativos\n",
        "# -----------------------------------------------------------------------------------------------\n",
        "#\n",
        "print(\"[INFO]\",\n",
        "    datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "    \"Creando la matriz de confusión vgg16...\")\n",
        "#\n",
        "# -----------------------------------------------------------------------------------------------\n",
        "# Creamos la matriz de confusión\n",
        "# -----------------------------------------------------------------------------------------------\n",
        "#\n",
        "predicted_classes_test_confusion = np.argmax(predicted_classes_test, axis=1)  \n",
        "#\n",
        "predicted_classes_test_confusion_cm = confusion_matrix(np.argmax(y_test_one_hot, axis=1),\n",
        "                                                       predicted_classes_test_confusion)\n",
        "#\n",
        "print(\"[INFO]\",\n",
        "    datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "    \"Visualizando la matriz de confusión...\")\n",
        "#\n",
        "# -----------------------------------------------------------------------------------------------\n",
        "# Visualizamos la matriz de confusión. Aquí se visualiza el desempeño del algoritmo.\n",
        "# Cada columna de la matriz representa el número de predicciones de cada etiqueta y \n",
        "# las filas la instancia de la etiqueta real.\n",
        "# -----------------------------------------------------------------------------------------------\n",
        "#\n",
        "predicted_classes_test_confusion_cm_df = pd.DataFrame(predicted_classes_test_confusion_cm,\n",
        "                                                      columns=labels,\n",
        "                                                      index=labels)\n",
        "#\n",
        "plt.figure(figsize = (20,14))  \n",
        "#\n",
        "sn.set(font_scale=2)                # Tamaño de fuente mapa calor\n",
        "sn.heatmap(predicted_classes_test_confusion_cm_df,\n",
        "           annot=True,              # Escribe el número de coincidencias en cada celda\n",
        "           linewidth=0.5,           # Ancho del borde de celdas de la tabla\n",
        "           cmap=\"YlOrRd\",           # Mapa de color amarillo - naranja - rojo\n",
        "           square=True,             # Forzar tamaño celdas\n",
        "           annot_kws={\"size\": 20})  # Tamaño de fuente barra\n",
        "plt.title('Matriz de confusión vgg16', pad=100, fontsize = 30, color='Black', fontstyle='italic')\n",
        "plt.savefig(directory_log + 'modelos/' + 'Matrizdeconfusion_en_vgg16.png')  \n",
        "\n",
        "plt.show() \n",
        "#"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOOFxcL8Op5K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -----------------------------------------------------------------------------------------------\n",
        "# Visualizamos informe resumen de clasificación\n",
        "# -----------------------------------------------------------------------------------------------\n",
        "#\n",
        "cm_report = classification_report(np.argmax(y_test_one_hot, axis=1),\n",
        "                                predicted_classes_test_confusion,\n",
        "                                target_names = labels)  \n",
        "#\n",
        "print(\"[INFO]\", \n",
        "    datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "    \"Informe de clasificación\")\n",
        "print(cm_report)\n",
        "#"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQPYQF3QPfls",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -----------------------------------------------------------------------------------------------\n",
        "# Inicio del proceso\n",
        "# -----------------------------------------------------------------------------------------------\n",
        "print(\"[INFO]\", \n",
        "    datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "    \"Inicio del proceso\",\n",
        "    \"save_model\")\n",
        "\n",
        "#    os.path.basename(__file__))\n",
        "#\n",
        "# -----------------------------------------------------------------------------------------------\n",
        "# Proceso principal: guarda las estadísticas del modelo \"model\" \n",
        "# en un archivo con nombre \"model_name\"\n",
        "# -----------------------------------------------------------------------------------------------\n",
        "#\n",
        "def save_model(directory_log,model_name,model):\n",
        "#\n",
        "    try:\n",
        "        #creamos el directorio destino si no existe \n",
        "        try:\n",
        "            os.stat(directory_log + 'modelos')\n",
        "        except:\n",
        "            os.mkdir(directory_log + 'modelos')\n",
        "#\n",
        "        with open(directory_log + 'modelos/' + model_name + '.stats', 'wb') as file_modelo:  \n",
        "            pickle.dump(model.history, file_modelo)\n",
        "#\n",
        "        print(\"[INFO]\", \n",
        "            datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "            \"Modelo correctamente guardado... \",\n",
        "            model_name)\n",
        "#\n",
        "    except Exception as e: # Controla cualquier error que se produzca en la función\n",
        "        print(\"[ERROR]\",\n",
        "            datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "            sys.exc_info()[0],\n",
        "            sys.exc_info()[1],\n",
        "            sys.exc_info()[2])\n",
        "#\n",
        "    print(\"[INFO]\", \n",
        "        datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "        \"Fin del proceso\",\n",
        "        \"save_model\")\n",
        "    #    os.path.basename(__file__))\n",
        "    #\n",
        "    # -----------------------------------------------------------------------------------------------\n",
        "    # Fin de la ejecución\n",
        "    # -----------------------------------------------------------------------------------------------\n",
        "    #\n",
        "    return\n",
        "#\n",
        "# -----------------------------------------------------------------------------------------------\n",
        "# Fin del proceso\n",
        "# -----------------------------------------------------------------------------------------------\n",
        "#"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lSmooEwQB_W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -----------------------------------------------------------------------------------------------\n",
        "# Guardamos el modelo para después poder compararlos\n",
        "# -----------------------------------------------------------------------------------------------\n",
        "#\n",
        "print(\"[INFO]\", \n",
        "    datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "    \"Llamada al proceso TFGVOP_save_model \")\n",
        "#\n",
        "save_model(directory_log,'vgg16',vgg16)\n",
        "\n",
        "print(\"[INFO]\", \n",
        "    datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "    \"Fin del proceso\",\n",
        "     \"vgg16\")  \n",
        "#    os.path.basename(__file__))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}