{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-3bbdbabb13ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%Y-%m-%d %H:%M:%S\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;34m\"Inicio del proceso\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m     os.path.basename(__file__))\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;31m# -----------------------------------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------------------------------------------\n",
    "# Programa: TFGVOP_vgg16\n",
    "# Autor: vmoctavio\n",
    "# Fecha creación: 28/09/2019\n",
    "# Descripción: Proceso para detectar plagas en la hoja de la vid utilizando una red vgg16\n",
    "#              Los datos origen estarán en \"directory_root\", dentro de una estructura de \n",
    "#              carpetas, una por cada una de las diferentes plagas a detectar.\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "#\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "# Imports necesarios\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "#\n",
    "# API de alto nivel para procesos de Deep Learning\n",
    "import keras\n",
    "#\n",
    "# Uso de funciones del backend\n",
    "from keras import backend as K\n",
    "#\n",
    "# Uso de funciones de manejo de imágenes\n",
    "from keras.preprocessing import image\n",
    "#\n",
    "# Convertir una imagen en una matriz NumPy \n",
    "from keras.preprocessing.image import img_to_array\n",
    "#\n",
    "# Convierte un vector de clase (enteros) en una matriz de clase binaria\n",
    "from keras.utils import to_categorical\n",
    "#\n",
    "# Optimizar para compilar un modelo\n",
    "from keras.optimizers import Adam\n",
    "#\n",
    "# Usar comandos del sistema operativo ver si esto se borra\n",
    "import os\n",
    "#\n",
    "# Manejo de arrays \n",
    "import numpy as np\n",
    "#\n",
    "# Para manipular fechas y horas\n",
    "import datetime\n",
    "#\n",
    "# Funciones matemáticas \n",
    "import math\n",
    "#\n",
    "# Librería para generar gráficas\n",
    "import matplotlib.pyplot as plt\n",
    "#\n",
    "# Entorno de trabajo para redes deep learning\n",
    "import tensorflow as tf\n",
    "#\n",
    "# Arquitectura de red a probar\n",
    "from tensorflow.keras.applications import vgg16\n",
    "#\n",
    "# Convierte un modelo de Keras a diagrama y lo guarda en un archivo\n",
    "from tensorflow.keras.utils import plot_model \n",
    "#\n",
    "# Dividir un dataset en dos\n",
    "from sklearn.model_selection import train_test_split\n",
    "#\n",
    "# Visualizar la matriz de confusión - rendimiento de un algoritmo\n",
    "from sklearn.metrics import confusion_matrix  \n",
    "#\n",
    "# Visualizar informe con las principales métricas de clasificación\n",
    "from sklearn.metrics import classification_report  \n",
    "#\n",
    "# Librería para el análisis de datos\n",
    "import pandas as pd  \n",
    "#\n",
    "# Librería para visualización de datos y gráficos\n",
    "import seaborn as sn  \n",
    "#\n",
    "# Librería para leer archivo de configuración\n",
    "import configparser\n",
    "#\n",
    "# Módulo para control de excepciones\n",
    "import sys\n",
    "#\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "# Inicio del proceso\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "print(\"[INFO]\", \n",
    "    datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "    \"Inicio del proceso\",\n",
    "    os.path.basename(__file__))\n",
    "#\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "# Comprobamos si existe archivo ini y en caso contrario paramos el programa\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "#\n",
    "try:\n",
    "    os.stat('TFGVOP_Config.ini')\n",
    "except Exception as e: # Controla que no exista el fichero\n",
    "    print(\"[ERROR]\",\n",
    "          datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "          \"No existe el fichero de configuración\",\n",
    "          sys.exc_info()[0],\n",
    "          sys.exc_info()[1],\n",
    "          sys.exc_info()[2])    \n",
    "    sys.exit()\n",
    "#\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "# Leemos archivo ini e inicializamos variables\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "#\n",
    "print(\"[INFO]\", \n",
    "    datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "    \"Leyendo archivo de configuración...\")\n",
    "#\n",
    "config = configparser.ConfigParser()\n",
    "config.read('TFGVOP_Config.ini')\n",
    "#\n",
    "# Directorio de trabajo donde está el dataset\n",
    "directory_root = config.get('config','directory_root')\n",
    "# Directorio de trabajo donde se generan los logs de salida del proceso\n",
    "directory_log = config.get('config','directory_log')\n",
    "# Número de veces que se entrena la red\n",
    "EPOCHS = int(config.get('config','EPOCHS'))\n",
    "# Initial Learning Rate\n",
    "INIT_LR = float(config.get('config','INIT_LR'))\n",
    "# Tamaño del lote\n",
    "BATCH_SIZE = int(config.get('config','BATCH_SIZE'))\n",
    "# Tamaño de la imagen: ancho\n",
    "width = int(config.get('config','width'))\n",
    "# Tamaño de la imagen: alto\n",
    "height = int(config.get('config','height'))\n",
    "# Número de canales de la imagen\n",
    "depth = int(config.get('config','depth'))\n",
    "# Porcentaje división dataset en train y test\n",
    "TEST_SIZE = float(config.get('config','TEST_SIZE'))\n",
    "# Porcentaje división dataset en train y validation (a partir del subconjunto anterior)\n",
    "VALID_SIZE = float(config.get('config','VALID_SIZE'))\n",
    "# Division del dataset no aleatorio\n",
    "RANDOM_STATE = int(config.get('config','RANDOM_STATE'))\n",
    "# Training progress\n",
    "VERBOSE = int(config.get('config','VERBOSE'))\n",
    "#\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "# Inicialización de variables\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "#\n",
    "image_list=[]       # array de array's resultado de convertir las imágenes del directorio\n",
    "image_labels=[]     # array de array's de etiquetas\n",
    "labels=[]           # array con las distintas etiquetas del dataset\n",
    "#\n",
    "# Intervalo para las coordenadas de la gráfica\n",
    "INTERVALO = math.ceil(EPOCHS/10)\n",
    "#\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "# Llamada a la función load_dataset_process para cargar arrays de imágenes y etiquetas\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "#\n",
    "# Función para cargar un Dataset a partir de un determinadao directorio\n",
    "import TFGVOP_load_dataset\n",
    "#\n",
    "print(\"[INFO]\", \n",
    "    datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "    \"Llamada al proceso TFGVOP_load_dataset \")\n",
    "#\n",
    "(image_labels,image_list,labels) = TFGVOP_load_dataset.load_dataset_process(directory_root)\n",
    "#\n",
    "print(\"[INFO]\", \n",
    "    datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "    \"Imágenes cargadas. Número total de imágenes para procesar:  \",\n",
    "    len(image_list),\n",
    "    \". Número total de clases diferentes:\",\n",
    "    len(labels))\n",
    "#\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "# Calculamos el número de clases diferentes\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "#\n",
    "n_classes = len(labels)\n",
    "#\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "# Convertir la lista de imágenes y etiquetas en arrays Numpy\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "#\n",
    "np_image_list = np.array(image_list, dtype=np.uint8)\n",
    "y = np.array(image_labels)\n",
    "#\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "# División de los datos (imágenes y etiquetas) \n",
    "# en archivos para entrenamiento (train) y pruebas (test)\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "#\n",
    "print(\"[INFO]\", \n",
    "    datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "    \"Dividiendo datos en train y test...\")\n",
    "#\n",
    "x_train, x_test, y_train, y_test = train_test_split(np_image_list,          # array de imágenes\n",
    "                                                    y,                      # array de etiquetas\n",
    "                                                    test_size=TEST_SIZE,    # % para el archivo de test \n",
    "                                                    random_state = RANDOM_STATE)\n",
    "#\n",
    "print(\"[INFO]\", \n",
    "    datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "    \"Training data shape (x_train): \",\n",
    "    x_train.shape)\n",
    "print(\"[INFO]\", \n",
    "    datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "    \"Training data shape (y_train): \",\n",
    "    y_train.shape)\n",
    "#\n",
    "print(\"[INFO]\", \n",
    "    datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "    \"Testing data shape (x_test): \",\n",
    "    x_test.shape)\n",
    "print(\"[INFO]\", \n",
    "    datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "    \"Testing data shape (y_test): \",\n",
    "    y_test.shape)\n",
    "#\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "# Cambiamos los tipos y escalamos los pixeles en el ranto [0,1]\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "#\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train = x_train / 255.\n",
    "x_test = x_test / 255.\n",
    "#\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "# Convierte un vector de clase (enteros) en una matriz de clase binaria\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "# \n",
    "y_train_one_hot = to_categorical(y_train)\n",
    "y_test_one_hot = to_categorical(y_test)\n",
    "#\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "# División de los datos (imágenes y etiquetas) \n",
    "# en archivos para entrenamiento (train) y validación (valid)\n",
    "# a partir de los archivos de entrenamiento que se generaron en la primera división.\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "#\n",
    "print(\"[INFO]\",\n",
    "    datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "    \"Dividiendo datos en train y valid...\")\n",
    "#\n",
    "x_train, x_valid, train_label, valid_label = train_test_split(x_train,          # array de imágenes \n",
    "                                                    y_train_one_hot,            # array de etiquetas\n",
    "                                                    test_size=VALID_SIZE,       # % para el archivo de validación  \n",
    "                                                    random_state = RANDOM_STATE)\n",
    "#\n",
    "print(\"[INFO]\", \n",
    "    datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "    \"Training data shape (x_train): \",\n",
    "    x_train.shape)\n",
    "print(\"[INFO]\", \n",
    "    datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "    \"Training data shape (train_label): \",\n",
    "    train_label.shape)\n",
    "#\n",
    "print(\"[INFO]\", \n",
    "    datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "    \"Validating data shape (x_valid): \",\n",
    "    x_valid.shape)\n",
    "print(\"[INFO]\", \n",
    "    datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "    \"Validating data shape (valid_label): \",\n",
    "    valid_label.shape)\n",
    "#\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "# Inicialización archivo de registro (LOG_DIR) y Tensorboard \n",
    "# -----------------------------------------------------------------------------------------------\n",
    "#\n",
    "LOG_DIR=directory_log + 'vgg16_' + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "# Frecuencia (en epochs) a la que se calculan los histogramas de activación para las capas del modelo.\n",
    "v_histogram_freq=1  \n",
    "#\n",
    "print(\"[INFO]\",\n",
    "    datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "    \"Generado log en... \",\n",
    "    LOG_DIR)\n",
    "#\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=LOG_DIR,      # Directorio de registro\n",
    "                                                    histogram_freq=v_histogram_freq,       \n",
    "                                                    write_graph=True,       # Si visualizar el gráfico\n",
    "                                                    write_images=True,      # Si visualizar imágenes\n",
    "                                                    update_freq='epoch',    # Las métricas se generan por cada epoch\n",
    "                                                    profile_batch=2)        # Perfilar el segundo lote\n",
    "#\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "# Inicializa input_shape en función del formato de la imagen\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "#\n",
    "inputShape = (height, width, depth)\n",
    "chanDim = -1\n",
    "if K.image_data_format() == \"channels_first\":\n",
    "    inputShape = (depth, height, width)\n",
    "    chanDim = 1\n",
    "#\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "# Función para crear el modelo vgg16\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "#\n",
    "def create_vgg16():\n",
    "    model = vgg16.VGG16(include_top=True,       # Incluir las 3 capas totalmente conectadas en la parte superior de la red\n",
    "                        weights=None,           # Inicialización random (no partir de pre-entrenadas de imagenet)\n",
    "                        input_tensor=None,      # No usar tensor como entrada de imágenes\n",
    "                        input_shape=inputShape, # Resolución de las imágenes de entrada\n",
    "                        pooling=None,           # Modo agrupación de características\n",
    "                        classes=n_classes)      # Número de clases\n",
    "    return model\n",
    "#\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "# Llamada a la función para crear el modelo\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "#\n",
    "vgg16_model = create_vgg16()  \n",
    "#\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "# Inicializa parámetros para el optimizador ADAM \n",
    "# -----------------------------------------------------------------------------------------------\n",
    "#\n",
    "opt = tf.keras.optimizers.Adam(lr=INIT_LR,                  # Initial Learning Rate\n",
    "                               decay=INIT_LR / EPOCHS)      # Disminución de Learning Rate \n",
    "#\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "# Configuración / compilación del proceso de aprendizaje\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "#\n",
    "vgg16_model.compile(loss='categorical_crossentropy',    # Función de pérdida\n",
    "                    optimizer=opt,                      # Optimizador \n",
    "                    metrics=['acc', 'mse'])             # Métricas del proceso \n",
    "#\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "# Imprime una representación resumida del modelo\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "#\n",
    "vgg16_model.summary()\n",
    "#\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "# Creamos el directorio destino de las gráficas, si no existe \n",
    "# -----------------------------------------------------------------------------------------------\n",
    "try:\n",
    "    os.stat(directory_log + 'modelos')\n",
    "except:\n",
    "    os.mkdir(directory_log + 'modelos')\n",
    "#\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "# Convierte un modelo de Keras a diagrama y lo guarda en un archivo\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "#\n",
    "tf.keras.utils.plot_model(model=vgg16_model,\n",
    "                       to_file=directory_log + 'modelos/' + 'Plotmodel_vgg16.png',\n",
    "                       show_shapes=True,\n",
    "                       show_layer_names=True,\n",
    "                       rankdir='TB',\n",
    "                       expand_nested=True,\n",
    "                       dpi=96)\n",
    "#\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "# Ejecución / entrenamiento de la red\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "#\n",
    "vgg16 = vgg16_model.fit(x_train,                                    # Imágenes de entrenamiento\n",
    "                        train_label,                                # Etiquetas entrenamiento \n",
    "                        batch_size=BATCH_SIZE,                      # Tamaño del lote \n",
    "                        epochs=EPOCHS,                              # Número de veces que se entrena la red\n",
    "                        verbose=VERBOSE,                            # Barra de progreso \n",
    "                        validation_data=(x_valid, valid_label),     # Datos de validación (imágenes y etiquetas)\n",
    "                        shuffle=True,                               # Reordenar los lotes al comienzo de cada epoch\n",
    "                        callbacks=[tensorboard_callback])           # Configuración de Tensorboard   \n",
    "#\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "# Representación de las métricas de entrenamiento y validación\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "#                               Training Accuracy vs Validation Accuracy\n",
    "plt.figure(0)  \n",
    "plt.plot(vgg16.history['acc'],'r')  \n",
    "plt.plot(vgg16.history['val_acc'],'g')  \n",
    "plt.xticks(np.arange(0, EPOCHS, INTERVALO))\n",
    "plt.rcParams['figure.figsize'] = (8, 6)  \n",
    "plt.xlabel(\"Num of Epochs\")  \n",
    "plt.ylabel(\"Accuracy\")  \n",
    "plt.title(\"Training Accuracy vs Validation Accuracy en vgg16\")  \n",
    "plt.legend(['train','validation'])\n",
    "plt.savefig(directory_log + 'modelos/' + 'TrainingAccuracyvsValidationAccuracy_en_vgg16.png')  \n",
    "\n",
    "#                               Training Loss vs Validation Loss\n",
    "plt.figure(1)  \n",
    "plt.plot(vgg16.history['loss'],'r')  \n",
    "plt.plot(vgg16.history['val_loss'],'g')  \n",
    "plt.xticks(np.arange(0, EPOCHS, INTERVALO))\n",
    "plt.rcParams['figure.figsize'] = (8, 6)  \n",
    "plt.xlabel(\"Num of Epochs\")  \n",
    "plt.ylabel(\"Loss\")  \n",
    "plt.title(\"Training Loss vs Validation Loss en vgg16\")  \n",
    "plt.legend(['train','validation'])\n",
    "plt.savefig(directory_log + 'modelos/' + 'TrainingLossvsValidationLoss_en_vgg16.png')  \n",
    "\n",
    "#                               Training mse vs Validation mse\n",
    "plt.figure(2)  \n",
    "plt.plot(vgg16.history['mse'],'r')  \n",
    "plt.plot(vgg16.history['val_mse'],'g')  \n",
    "plt.xticks(np.arange(0, EPOCHS, INTERVALO))\n",
    "plt.rcParams['figure.figsize'] = (8, 6)  \n",
    "plt.xlabel(\"Num of Epochs\")  \n",
    "plt.ylabel(\"MSE\")  \n",
    "plt.title(\"Training mse vs Validation mse en vgg16\")  \n",
    "plt.legend(['train','validation'])\n",
    "plt.savefig(directory_log + 'modelos/' + 'TrainingmsevsValidationmse_en_vgg16.png')  \n",
    "#\n",
    "plt.show()\n",
    "#\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "# Calcular la precisión del modelo con el conjunto de datos de test \n",
    "# los cuales no han participado en el proceso de entrenamiento y validación\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "#\n",
    "print(\"[INFO]\",\n",
    "    datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "    \"Calculando la precisión del modelo vgg16... \")\n",
    "#\n",
    "resultado_test = vgg16_model.evaluate(x_test,\n",
    "                              y_test_one_hot)\n",
    "#\n",
    "print(\"[INFO]\",\n",
    "    datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "    f\"Test Accuracy vgg16: {resultado_test[1]*100}\")\n",
    "#\n",
    "print(\"[INFO]\",\n",
    "    datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "    f\"Test Loss vgg16: {resultado_test[0]*100}\")  # no sé si el loss se multiplica o no\n",
    "#\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "# Genera las predicciones de salida para el conjunto de datos test\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "#\n",
    "predicted_classes_test = vgg16_model.predict(x_test)\n",
    "#\n",
    "predicted_classes=[]\n",
    "for predicted_image in predicted_classes_test:\n",
    "    predicted_classes.append(predicted_image.tolist().index(max(predicted_image)))\n",
    "#\n",
    "predicted_classes=np.array(predicted_classes)\n",
    "#\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "# Convertir array de etiquetas de test\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "#\n",
    "y_test_aux = np.array(y_test)\n",
    "#\n",
    "predicted_classes.shape, y_test.shape\n",
    "#\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "# Calcular predicciones correctas\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "#\n",
    "correct = np.where(predicted_classes==y_test)[0]\n",
    "#\n",
    "print(\"[INFO]\",\n",
    "    datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "    \"Se han encontrado %d etiquetas correctas\" % len(correct))\n",
    "#\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "# Ejemplos de predicciones correctas\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "#\n",
    "for i, correct in enumerate(correct[0:9]):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.imshow(x_test[correct].reshape(256,256,3), cmap='gray', interpolation='none')\n",
    "    plt.title(\"{} / {}\".format(labels[predicted_classes[correct]],labels[y_test[correct]]))\n",
    "    plt.tight_layout()\n",
    "#\n",
    "plt.savefig(directory_log + 'modelos/' + 'Ejemploprediccionescorrectas_en_vgg16.png')  \n",
    "plt.show()  \n",
    "#\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "# Calcular predicciones incorrectas\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "#\n",
    "incorrect = np.where(predicted_classes!=y_test)[0]\n",
    "#\n",
    "print(\"[INFO]\",\n",
    "    datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "    \"Se han encontrado %d etiquetas incorrectas\" % len(incorrect))\n",
    "#\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "# Ejemplos de predicciones incorrecatas\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "#\n",
    "# print(\"Calculado / Correcto\")\n",
    "for i, incorrect in enumerate(incorrect[0:9]):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.imshow(x_test[incorrect].reshape(256,256,3), cmap='gray', interpolation='none')\n",
    "    plt.title(\"{} / {}\".format(labels[predicted_classes[incorrect]],labels[y_test[incorrect]]))\n",
    "    plt.tight_layout()\n",
    "#\n",
    "plt.savefig(directory_log + 'modelos/' + 'Ejemploprediccionesincorrectas_en_vgg16.png')  \n",
    "plt.show()  \n",
    "#\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "# Matriz de confusión para evaluación de falsos positivos y falsos negativos\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "#\n",
    "print(\"[INFO]\",\n",
    "    datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "    \"Creando la matriz de confusión vgg16...\")\n",
    "#\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "# Creamos la matriz de confusión\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "#\n",
    "predicted_classes_test_confusion = np.argmax(predicted_classes_test, axis=1)  \n",
    "#\n",
    "predicted_classes_test_confusion_cm = confusion_matrix(np.argmax(y_test_one_hot, axis=1),\n",
    "                                                       predicted_classes_test_confusion)\n",
    "#\n",
    "print(\"[INFO]\",\n",
    "    datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "    \"Visualizando la matriz de confusión...\")\n",
    "#\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "# Visualizamos la matriz de confusión. Aquí se visualiza el desempeño del algoritmo.\n",
    "# Cada columna de la matriz representa el número de predicciones de cada etiqueta y \n",
    "# las filas la instancia de la etiqueta real.\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "#\n",
    "predicted_classes_test_confusion_cm_df = pd.DataFrame(predicted_classes_test_confusion_cm,\n",
    "                                                      columns=labels,\n",
    "                                                      index=labels)\n",
    "#\n",
    "plt.figure(figsize = (20,14))  \n",
    "#\n",
    "sn.set(font_scale=2)                # Tamaño de fuente mapa calor\n",
    "sn.heatmap(predicted_classes_test_confusion_cm_df,\n",
    "           annot=True,              # Escribe el número de coincidencias en cada celda\n",
    "           linewidth=0.5,           # Ancho del borde de celdas de la tabla\n",
    "           cmap=\"YlOrRd\",           # Mapa de color amarillo - naranja - rojo\n",
    "           square=True,             # Forzar tamaño celdas\n",
    "           annot_kws={\"size\": 20})  # Tamaño de fuente barra\n",
    "plt.title('Matriz de confusión vgg16', pad=100, fontsize = 30, color='Black', fontstyle='italic')\n",
    "plt.savefig(directory_log + 'modelos/' + 'Matrizdeconfusion_en_vgg16.png')  \n",
    "\n",
    "plt.show() \n",
    "#\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "# Visualizamos informe resumen de clasificación\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "#\n",
    "cm_report = classification_report(np.argmax(y_test_one_hot, axis=1),\n",
    "                                predicted_classes_test_confusion,\n",
    "                                target_names = labels)  \n",
    "#\n",
    "print(\"[INFO]\", \n",
    "    datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "    \"Informe de clasificación\")\n",
    "print(cm_report)\n",
    "#\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "# Guardamos el modelo para después poder compararlos\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "#\n",
    "print(\"[INFO]\", \n",
    "    datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "    \"Llamada al proceso TFGVOP_save_model \")\n",
    "#\n",
    "import TFGVOP_save_model\n",
    "#\n",
    "TFGVOP_save_model.save_model(directory_log,'vgg16',vgg16)\n",
    "\n",
    "print(\"[INFO]\", \n",
    "    datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "    \"Fin del proceso\",\n",
    "    os.path.basename(__file__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
