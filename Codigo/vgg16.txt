[INFO] 2019-10-13 14:50:51 Inicio del proceso TFGVOP_vgg16.py
[INFO] 2019-10-13 14:50:51 Inicio del proceso TFGVOP_load_dataset.py
[INFO] 2019-10-13 14:50:51 Llamada al proceso TFGVOP_load_dataset 
[INFO] 2019-10-13 14:50:51 Procesando el directorio...  Healthy
[INFO] 2019-10-13 14:50:51 Total imágenes del directorio ...  Healthy 50
[INFO] 2019-10-13 14:50:51 Procesando el directorio...  Leaf_blight
[INFO] 2019-10-13 14:50:51 Total imágenes del directorio ...  Leaf_blight 50
[INFO] 2019-10-13 14:50:51 Procesando el directorio...  Blackrot
[INFO] 2019-10-13 14:50:51 Total imágenes del directorio ...  Blackrot 50
[INFO] 2019-10-13 14:50:51 Procesando el directorio...  Esca
[INFO] 2019-10-13 14:50:52 Total imágenes del directorio ...  Esca 50
[INFO] 2019-10-13 14:50:52 Proceso de carga de imágenes completado 
[INFO] 2019-10-13 14:50:52 Total Etiquetas...  4
[INFO] 2019-10-13 14:50:52 Fin del proceso TFGVOP_load_dataset.py
[INFO] 2019-10-13 14:50:52 Imágenes cargadas. Número total de imágenes para procesar:   200 . Número total de clases diferentes: 4
[INFO] 2019-10-13 14:50:52 Dividiendo datos en train y test...
[INFO] 2019-10-13 14:50:52 Training data shape (x_train):  (180, 256, 256, 3)
[INFO] 2019-10-13 14:50:52 Training data shape (y_train):  (180,)
[INFO] 2019-10-13 14:50:52 Testing data shape (x_test):  (20, 256, 256, 3)
[INFO] 2019-10-13 14:50:52 Testing data shape (y_test):  (20,)
[INFO] 2019-10-13 14:50:52 Dividiendo datos en train y valid...
[INFO] 2019-10-13 14:50:52 Training data shape (x_train):  (144, 256, 256, 3)
[INFO] 2019-10-13 14:50:52 Training data shape (train_label):  (144, 4)
[INFO] 2019-10-13 14:50:52 Validating data shape (x_valid):  (36, 256, 256, 3)
[INFO] 2019-10-13 14:50:52 Validating data shape (valid_label):  (36, 4)
[INFO] 2019-10-13 14:50:52 Generado log en...  /Users/vmoctavio/Downloads/keras-tutorial/logs/pruebavidcon/borrar/vgg16_20191013-145052
Model: "vgg16"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 256, 256, 3)]     0         
_________________________________________________________________
block1_conv1 (Conv2D)        (None, 256, 256, 64)      1792      
_________________________________________________________________
block1_conv2 (Conv2D)        (None, 256, 256, 64)      36928     
_________________________________________________________________
block1_pool (MaxPooling2D)   (None, 128, 128, 64)      0         
_________________________________________________________________
block2_conv1 (Conv2D)        (None, 128, 128, 128)     73856     
_________________________________________________________________
block2_conv2 (Conv2D)        (None, 128, 128, 128)     147584    
_________________________________________________________________
block2_pool (MaxPooling2D)   (None, 64, 64, 128)       0         
_________________________________________________________________
block3_conv1 (Conv2D)        (None, 64, 64, 256)       295168    
_________________________________________________________________
block3_conv2 (Conv2D)        (None, 64, 64, 256)       590080    
_________________________________________________________________
block3_conv3 (Conv2D)        (None, 64, 64, 256)       590080    
_________________________________________________________________
block3_pool (MaxPooling2D)   (None, 32, 32, 256)       0         
_________________________________________________________________
block4_conv1 (Conv2D)        (None, 32, 32, 512)       1180160   
_________________________________________________________________
block4_conv2 (Conv2D)        (None, 32, 32, 512)       2359808   
_________________________________________________________________
block4_conv3 (Conv2D)        (None, 32, 32, 512)       2359808   
_________________________________________________________________
block4_pool (MaxPooling2D)   (None, 16, 16, 512)       0         
_________________________________________________________________
block5_conv1 (Conv2D)        (None, 16, 16, 512)       2359808   
_________________________________________________________________
block5_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   
_________________________________________________________________
block5_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   
_________________________________________________________________
block5_pool (MaxPooling2D)   (None, 8, 8, 512)         0         
_________________________________________________________________
flatten (Flatten)            (None, 32768)             0         
_________________________________________________________________
fc1 (Dense)                  (None, 4096)              134221824 
_________________________________________________________________
fc2 (Dense)                  (None, 4096)              16781312  
_________________________________________________________________
predictions (Dense)          (None, 4)                 16388     
=================================================================
Total params: 165,734,212
Trainable params: 165,734,212
Non-trainable params: 0
_________________________________________________________________
Train on 144 samples, validate on 36 samples
Epoch 1/5
 32/144 [=====>........................] - ETA: 1:00 - loss: 1.3864 - acc: 0.1562 - mse: 0.1875 64/144 [============>.................] - ETA: 43s - loss: 1.3869 - acc: 0.1719 - mse: 0.1876  96/144 [===================>..........] - ETA: 26s - loss: 1.3865 - acc: 0.2083 - mse: 0.1875128/144 [=========================>....] - ETA: 8s - loss: 1.3862 - acc: 0.2109 - mse: 0.1875 144/144 [==============================] - 103s 713ms/sample - loss: 1.3861 - acc: 0.2222 - mse: 0.1875 - val_loss: 1.3870 - val_acc: 0.2500 - val_mse: 0.1876
Epoch 2/5
 32/144 [=====>........................] - ETA: 1:19 - loss: 1.3849 - acc: 0.3125 - mse: 0.1873 64/144 [============>.................] - ETA: 59s - loss: 1.3850 - acc: 0.2812 - mse: 0.1873  96/144 [===================>..........] - ETA: 35s - loss: 1.3846 - acc: 0.2812 - mse: 0.1873128/144 [=========================>....] - ETA: 11s - loss: 1.3852 - acc: 0.2500 - mse: 0.1874144/144 [==============================] - 129s 899ms/sample - loss: 1.3845 - acc: 0.2639 - mse: 0.1873 - val_loss: 1.3884 - val_acc: 0.2500 - val_mse: 0.1878
Epoch 3/5
 32/144 [=====>........................] - ETA: 58s - loss: 1.3815 - acc: 0.2188 - mse: 0.1869 64/144 [============>.................] - ETA: 42s - loss: 1.3812 - acc: 0.2969 - mse: 0.1869 96/144 [===================>..........] - ETA: 26s - loss: 1.3824 - acc: 0.2812 - mse: 0.1870128/144 [=========================>....] - ETA: 9s - loss: 1.3834 - acc: 0.2656 - mse: 0.1871 144/144 [==============================] - 107s 741ms/sample - loss: 1.3828 - acc: 0.2639 - mse: 0.1871 - val_loss: 1.3923 - val_acc: 0.2500 - val_mse: 0.1882
Epoch 4/5
 32/144 [=====>........................] - ETA: 57s - loss: 1.3804 - acc: 0.2812 - mse: 0.1868 64/144 [============>.................] - ETA: 42s - loss: 1.3812 - acc: 0.2969 - mse: 0.1869 96/144 [===================>..........] - ETA: 26s - loss: 1.3778 - acc: 0.2917 - mse: 0.1865128/144 [=========================>....] - ETA: 9s - loss: 1.3776 - acc: 0.2656 - mse: 0.1864 144/144 [==============================] - 106s 738ms/sample - loss: 1.3797 - acc: 0.2639 - mse: 0.1867 - val_loss: 1.3999 - val_acc: 0.2500 - val_mse: 0.1891
Epoch 5/5
 32/144 [=====>........................] - ETA: 56s - loss: 1.3933 - acc: 0.2188 - mse: 0.1883 64/144 [============>.................] - ETA: 42s - loss: 1.3777 - acc: 0.2031 - mse: 0.1865 96/144 [===================>..........] - ETA: 26s - loss: 1.3775 - acc: 0.2708 - mse: 0.1864128/144 [=========================>....] - ETA: 9s - loss: 1.3789 - acc: 0.2891 - mse: 0.1866 144/144 [==============================] - 106s 738ms/sample - loss: 1.3764 - acc: 0.2986 - mse: 0.1863 - val_loss: 1.4038 - val_acc: 0.3333 - val_mse: 0.1895
[INFO] 2019-10-13 15:39:33 Calculando la precisión del modelo vgg16... 
20/1 [========================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 4s 220ms/sample - loss: 1.4328 - acc: 0.1500 - mse: 0.1930
[INFO] 2019-10-13 15:39:38 Test Accuracy vgg16: 15.000000596046448
[INFO] 2019-10-13 15:39:38 Test Loss vgg16: 143.28433275222778
[INFO] 2019-10-13 15:39:41 Se han encontrado 3 etiquetas correctas
[INFO] 2019-10-13 15:39:45 Se han encontrado 17 etiquetas incorrectas
[INFO] 2019-10-13 15:39:48 Creando la matriz de confusión vgg16...
[INFO] 2019-10-13 15:39:48 Visualizando la matriz de confusión...
[INFO] 2019-10-13 15:39:50 Informe de clasificación
              precision    recall  f1-score   support

     Healthy       0.16      1.00      0.27         3
 Leaf_blight       0.00      0.00      0.00         7
    Blackrot       0.00      0.00      0.00         2
        Esca       0.00      0.00      0.00         8

    accuracy                           0.15        20
   macro avg       0.04      0.25      0.07        20
weighted avg       0.02      0.15      0.04        20

[INFO] 2019-10-13 15:39:50 Llamada al proceso TFGVOP_save_model 
[INFO] 2019-10-13 15:39:50 Inicio del proceso TFGVOP_save_model.py
[INFO] 2019-10-13 15:39:50 Modelo correcamente guardado...  vgg16
[INFO] 2019-10-13 15:39:50 Fin del proceso TFGVOP_save_model.py
[INFO] 2019-10-13 15:39:50 Fin del proceso TFGVOP_vgg16.py
