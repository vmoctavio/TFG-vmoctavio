{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the matplotlib backend so figures can be saved in the background\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")     # With this line = figure disappears; without this line = warning\n",
    "\n",
    "# ver si es necesaria esta línea y también el import matplotlib sólo o con la de abajo de .pyplot es suficiente.\n",
    "# este agg es para que guarde archivo. también se puede probar con\n",
    "# plt.plot(x,y)\n",
    "# plt.savefig('path/figure_filename.jpg',dpi=300)\n",
    "# porque más abajo se importa as plt otra vez.....  \n",
    "# se supone que el agg es para que pueda verse por pantalla la ejecución y pueda generarse como imagen\n",
    "\n",
    "\n",
    "\n",
    "print(\"[INFO] entro...\")\n",
    "\n",
    "\n",
    "# import the necessary packages\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "from keras.optimizers import SGD\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse # esto no sé si realmente hace falta....\n",
    "import random\n",
    "import pickle\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# construct the argument parser and parse the arguments\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-d\", \"--dataset\", required=True,\n",
    "\thelp=\"path to input dataset of images\")\n",
    "ap.add_argument(\"-m\", \"--model\", required=True,\n",
    "\thelp=\"path to output trained model\")\n",
    "ap.add_argument(\"-l\", \"--label-bin\", required=True,\n",
    "\thelp=\"path to output label binarizer\")\n",
    "ap.add_argument(\"-p\", \"--plot\", required=True,\n",
    "\thelp=\"path to output accuracy/loss plot\")\n",
    "args = vars(ap.parse_args())\n",
    "\n",
    "\n",
    "# initialize the data and labels\n",
    "print(\"[INFO] loading images...\")\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# grab the image paths and randomly shuffle them\n",
    "imagePaths = sorted(list(paths.list_images(args[\"dataset\"])))\n",
    "random.seed(42)\n",
    "random.shuffle(imagePaths)\n",
    "\n",
    "# loop over the input images\n",
    "for imagePath in imagePaths:\n",
    "\t# load the image, resize the image to be 32x32 pixels (ignoring\n",
    "\t# aspect ratio), flatten the image into 32x32x3=3072 pixel image\n",
    "\t# into a list, and store the image in the data list\n",
    "\timage = cv2.imread(imagePath)\n",
    "\timage = cv2.resize(image, (32, 32)).flatten()\n",
    "\tdata.append(image)\n",
    "\n",
    "\t# extract the class label from the image path and update the\n",
    "\t# labels list\n",
    "\tlabel = imagePath.split(os.path.sep)[-2]\n",
    "\tlabels.append(label)\n",
    "    \n",
    "    \n",
    "# scale the raw pixel intensities to the range [0, 1]\n",
    "data = np.array(data, dtype=\"float\") / 255.0\n",
    "labels = np.array(labels)\n",
    "\n",
    "\n",
    "# partition the data into training and testing splits using 75% of\n",
    "# the data for training and the remaining 25% for testing\n",
    "(trainX, testX, trainY, testY) = train_test_split(data,\n",
    "\tlabels, test_size=0.25, random_state=42)\n",
    "\n",
    "# convert the labels from integers to vectors (for 2-class, binary\n",
    "# classification you should use Keras' to_categorical function\n",
    "# instead as the scikit-learn's LabelBinarizer will not return a\n",
    "# vector)\n",
    "lb = LabelBinarizer()\n",
    "trainY = lb.fit_transform(trainY)\n",
    "testY = lb.transform(testY)\n",
    "\n",
    "# define the 3072-1024-512-3 architecture using Keras\n",
    "model = Sequential()\n",
    "model.add(Dense(1024, input_shape=(3072,), activation=\"sigmoid\"))\n",
    "model.add(Dense(512, activation=\"sigmoid\"))\n",
    "model.add(Dense(len(lb.classes_), activation=\"softmax\"))\n",
    "\n",
    "# initialize our initial learning rate and # of epochs to train for\n",
    "INIT_LR = 0.01\n",
    "EPOCHS = 75\n",
    "\n",
    "# compile the model using SGD as our optimizer and categorical\n",
    "# cross-entropy loss (you'll want to use binary_crossentropy\n",
    "# for 2-class classification)\n",
    "print(\"[INFO] training network...\")\n",
    "opt = SGD(lr=INIT_LR)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
    "\tmetrics=[\"accuracy\"])\n",
    "\n",
    "# train the neural network\n",
    "H = model.fit(trainX, trainY, validation_data=(testX, testY),\n",
    "\tepochs=EPOCHS, batch_size=32)\n",
    "\n",
    "# evaluate the network\n",
    "print(\"[INFO] evaluating network...\")\n",
    "predictions = model.predict(testX, batch_size=32)\n",
    "print(classification_report(testY.argmax(axis=1),\n",
    "\tpredictions.argmax(axis=1), target_names=lb.classes_))\n",
    "\n",
    "# plot the training loss and accuracy\n",
    "N = np.arange(0, EPOCHS)\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(N, H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(N, H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(N, H.history[\"acc\"], label=\"train_acc\")\n",
    "plt.plot(N, H.history[\"val_acc\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy (Simple NN)\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend()\n",
    "plt.savefig(args[\"plot\"])\n",
    "\n",
    "# save the model and label binarizer to disk\n",
    "print(\"[INFO] serializing network and label binarizer...\")\n",
    "model.save(args[\"model\"])\n",
    "f = open(args[\"label_bin\"], \"wb\")\n",
    "f.write(pickle.dumps(lb))\n",
    "f.close()\n",
    "\n",
    "# import the necessary packages\n",
    "from keras.models import load_model\n",
    "import argparse\n",
    "import pickle\n",
    "import cv2\n",
    "\n",
    "# construct the argument parser and parse the arguments\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-i\", \"--image\", required=True,\n",
    "\thelp=\"path to input image we are going to classify\")\n",
    "ap.add_argument(\"-m\", \"--model\", required=True,\n",
    "\thelp=\"path to trained Keras model\")\n",
    "ap.add_argument(\"-l\", \"--label-bin\", required=True,\n",
    "\thelp=\"path to label binarizer\")\n",
    "ap.add_argument(\"-w\", \"--width\", type=int, default=28,\n",
    "\thelp=\"target spatial dimension width\")\n",
    "ap.add_argument(\"-e\", \"--height\", type=int, default=28,\n",
    "\thelp=\"target spatial dimension height\")\n",
    "ap.add_argument(\"-f\", \"--flatten\", type=int, default=-1,\n",
    "\thelp=\"whether or not we should flatten the image\")\n",
    "args = vars(ap.parse_args())\n",
    "\n",
    "# load the input image and resize it to the target spatial dimensions\n",
    "image = cv2.imread(args[\"image\"])\n",
    "output = image.copy()\n",
    "image = cv2.resize(image, (args[\"width\"], args[\"height\"]))\n",
    "\n",
    "# scale the pixel values to [0, 1]\n",
    "image = image.astype(\"float\") / 255.0\n",
    "\n",
    "# check to see if we should flatten the image and add a batch\n",
    "# dimension\n",
    "if args[\"flatten\"] > 0:\n",
    "\timage = image.flatten()\n",
    "\timage = image.reshape((1, image.shape[0]))\n",
    "\n",
    "# otherwise, we must be working with a CNN -- don't flatten the\n",
    "# image, simply add the batch dimension\n",
    "else:\n",
    "\timage = image.reshape((1, image.shape[0], image.shape[1],\n",
    "\t\timage.shape[2]))\n",
    "    \n",
    "# load the model and label binarizer\n",
    "print(\"[INFO] loading network and label binarizer...\")\n",
    "model = load_model(args[\"model\"])\n",
    "lb = pickle.loads(open(args[\"label_bin\"], \"rb\").read())\n",
    "\n",
    "# make a prediction on the image\n",
    "preds = model.predict(image)\n",
    "\n",
    "# find the class label index with the largest corresponding\n",
    "# probability\n",
    "i = preds.argmax(axis=1)[0]\n",
    "label = lb.classes_[i]\n",
    "\n",
    "# draw the class label + probability on the output image\n",
    "text = \"{}: {:.2f}%\".format(label, preds[0][i] * 100)\n",
    "cv2.putText(output, text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7,\n",
    "\t(0, 0, 255), 2)\n",
    "\n",
    "# show the output image\n",
    "cv2.imshow(\"Image\", output)\n",
    "cv2.waitKey(0)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
